{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d453b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5f62821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data ready\n",
    "# Generate train dummy data for 1000 Students and dummy test for 500\n",
    "#Columns :Age, Hours of Study & Avg Previous test scores\n",
    "np.random.seed(2018)\n",
    "train_data, test_data = np.random.random((1000, 3)), np.random.random((500, 3))\n",
    "#Generate dummy results for 1000 students : Whether Passed (1) or Failed (0)\n",
    "labels = np.random.randint(2, size=(1000, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5907c228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88234931, 0.10432774, 0.90700933],\n",
       "       [0.3063989 , 0.44640887, 0.58998539],\n",
       "       [0.8371111 , 0.69780061, 0.80280284],\n",
       "       ...,\n",
       "       [0.76474832, 0.12224649, 0.06019634],\n",
       "       [0.21847107, 0.57064847, 0.27701246],\n",
       "       [0.97785211, 0.81210972, 0.34780075]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b797332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35981783, 0.64707122, 0.16858627],\n",
       "       [0.95089881, 0.24401454, 0.39478811],\n",
       "       [0.99185888, 0.01995682, 0.19105642],\n",
       "       ...,\n",
       "       [0.03335012, 0.35559007, 0.5386409 ],\n",
       "       [0.3804594 , 0.11970055, 0.08783101],\n",
       "       [0.83887832, 0.26936355, 0.90847875]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6c91d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the model structure with the required layers, # of neurons, activation function and optimizers\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=3, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2e0f28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49\n",
      "Trainable params: 49\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcdc10cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.7693 - accuracy: 0.5090\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7260 - accuracy: 0.5140\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7083 - accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7008 - accuracy: 0.4910\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6974 - accuracy: 0.4930\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.4900\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.4850\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.4830\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.4900\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.4860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17bd2cb7c70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model and make predictions\n",
    "model.fit(train_data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8e7cc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#Make predictions from the trained model\n",
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "141cef18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4913262 ],\n",
       "       [0.51029253],\n",
       "       [0.51137066],\n",
       "       [0.5076523 ],\n",
       "       [0.4618711 ],\n",
       "       [0.50934845],\n",
       "       [0.51407677],\n",
       "       [0.52173245],\n",
       "       [0.5000896 ],\n",
       "       [0.515321  ],\n",
       "       [0.47198936],\n",
       "       [0.4810569 ],\n",
       "       [0.46111536],\n",
       "       [0.47689116],\n",
       "       [0.5172146 ],\n",
       "       [0.4935028 ],\n",
       "       [0.49267974],\n",
       "       [0.44960904],\n",
       "       [0.4913547 ],\n",
       "       [0.48876303],\n",
       "       [0.51087844],\n",
       "       [0.43223456],\n",
       "       [0.5108213 ],\n",
       "       [0.48795733],\n",
       "       [0.52173245],\n",
       "       [0.5065291 ],\n",
       "       [0.4740712 ],\n",
       "       [0.4815635 ],\n",
       "       [0.46127743],\n",
       "       [0.45294383],\n",
       "       [0.49242994],\n",
       "       [0.4942819 ],\n",
       "       [0.47630668],\n",
       "       [0.5015189 ],\n",
       "       [0.48571885],\n",
       "       [0.5079881 ],\n",
       "       [0.4844302 ],\n",
       "       [0.487563  ],\n",
       "       [0.51966244],\n",
       "       [0.5135642 ],\n",
       "       [0.46049213],\n",
       "       [0.47077867],\n",
       "       [0.46173695],\n",
       "       [0.49462497],\n",
       "       [0.4787263 ],\n",
       "       [0.5146701 ],\n",
       "       [0.5148577 ],\n",
       "       [0.5143831 ],\n",
       "       [0.45327237],\n",
       "       [0.44114006],\n",
       "       [0.4608172 ],\n",
       "       [0.50248235],\n",
       "       [0.50982463],\n",
       "       [0.51595384],\n",
       "       [0.50173455],\n",
       "       [0.4678386 ],\n",
       "       [0.5156381 ],\n",
       "       [0.50441563],\n",
       "       [0.5217183 ],\n",
       "       [0.51616985],\n",
       "       [0.48784956],\n",
       "       [0.4705514 ],\n",
       "       [0.48054713],\n",
       "       [0.5005065 ],\n",
       "       [0.5161918 ],\n",
       "       [0.5018302 ],\n",
       "       [0.4997757 ],\n",
       "       [0.4858852 ],\n",
       "       [0.5054676 ],\n",
       "       [0.5161021 ],\n",
       "       [0.51945156],\n",
       "       [0.5198618 ],\n",
       "       [0.51816994],\n",
       "       [0.46399048],\n",
       "       [0.4689744 ],\n",
       "       [0.4812177 ],\n",
       "       [0.48789075],\n",
       "       [0.4897116 ],\n",
       "       [0.5149826 ],\n",
       "       [0.5147047 ],\n",
       "       [0.503471  ],\n",
       "       [0.5066396 ],\n",
       "       [0.47610274],\n",
       "       [0.51212287],\n",
       "       [0.50452805],\n",
       "       [0.516856  ],\n",
       "       [0.45323464],\n",
       "       [0.50172853],\n",
       "       [0.50294673],\n",
       "       [0.50830656],\n",
       "       [0.52173245],\n",
       "       [0.50453895],\n",
       "       [0.5149681 ],\n",
       "       [0.4927443 ],\n",
       "       [0.47322527],\n",
       "       [0.4995864 ],\n",
       "       [0.51011395],\n",
       "       [0.4574949 ],\n",
       "       [0.43603453],\n",
       "       [0.4651087 ],\n",
       "       [0.48459512],\n",
       "       [0.5143114 ],\n",
       "       [0.45396432],\n",
       "       [0.46154964],\n",
       "       [0.49565294],\n",
       "       [0.45915055],\n",
       "       [0.521392  ],\n",
       "       [0.4882687 ],\n",
       "       [0.5052252 ],\n",
       "       [0.49618214],\n",
       "       [0.50780326],\n",
       "       [0.52173245],\n",
       "       [0.4810192 ],\n",
       "       [0.5114136 ],\n",
       "       [0.51641387],\n",
       "       [0.5203147 ],\n",
       "       [0.4763169 ],\n",
       "       [0.47394547],\n",
       "       [0.48894933],\n",
       "       [0.52173245],\n",
       "       [0.45992553],\n",
       "       [0.46371138],\n",
       "       [0.50687486],\n",
       "       [0.47391388],\n",
       "       [0.48449793],\n",
       "       [0.5122687 ],\n",
       "       [0.4869339 ],\n",
       "       [0.510662  ],\n",
       "       [0.52173245],\n",
       "       [0.46046996],\n",
       "       [0.51477253],\n",
       "       [0.51523656],\n",
       "       [0.42888626],\n",
       "       [0.45940292],\n",
       "       [0.49701917],\n",
       "       [0.5031591 ],\n",
       "       [0.52173245],\n",
       "       [0.52173245],\n",
       "       [0.47435784],\n",
       "       [0.5124646 ],\n",
       "       [0.49446365],\n",
       "       [0.48144472],\n",
       "       [0.51134354],\n",
       "       [0.50555515],\n",
       "       [0.4617101 ],\n",
       "       [0.5005287 ],\n",
       "       [0.52173245],\n",
       "       [0.52173245],\n",
       "       [0.5018934 ],\n",
       "       [0.5050246 ],\n",
       "       [0.5092714 ],\n",
       "       [0.50431764],\n",
       "       [0.48442045],\n",
       "       [0.49779138],\n",
       "       [0.5187373 ],\n",
       "       [0.5090945 ],\n",
       "       [0.51772624],\n",
       "       [0.49052975],\n",
       "       [0.5078712 ],\n",
       "       [0.5050268 ],\n",
       "       [0.4980169 ],\n",
       "       [0.49688584],\n",
       "       [0.50884306],\n",
       "       [0.4970884 ],\n",
       "       [0.4977558 ],\n",
       "       [0.44993713],\n",
       "       [0.51986986],\n",
       "       [0.4650131 ],\n",
       "       [0.52173245],\n",
       "       [0.52173245],\n",
       "       [0.50167763],\n",
       "       [0.45672145],\n",
       "       [0.46307805],\n",
       "       [0.50387156],\n",
       "       [0.52173245],\n",
       "       [0.5005886 ],\n",
       "       [0.50117636],\n",
       "       [0.51117784],\n",
       "       [0.4921345 ],\n",
       "       [0.4821554 ],\n",
       "       [0.48003328],\n",
       "       [0.49453822],\n",
       "       [0.5216101 ],\n",
       "       [0.51388186],\n",
       "       [0.49546918],\n",
       "       [0.47780576],\n",
       "       [0.5175699 ],\n",
       "       [0.50110686],\n",
       "       [0.46601403],\n",
       "       [0.5132944 ],\n",
       "       [0.5052641 ],\n",
       "       [0.4692366 ],\n",
       "       [0.50649714],\n",
       "       [0.46427613],\n",
       "       [0.50713533],\n",
       "       [0.5111768 ],\n",
       "       [0.50592744],\n",
       "       [0.5153515 ],\n",
       "       [0.50067294],\n",
       "       [0.50807357],\n",
       "       [0.5058822 ],\n",
       "       [0.49473995],\n",
       "       [0.46508533],\n",
       "       [0.50867176],\n",
       "       [0.5166928 ],\n",
       "       [0.5081301 ],\n",
       "       [0.51308745],\n",
       "       [0.49137843],\n",
       "       [0.4207799 ],\n",
       "       [0.47747418],\n",
       "       [0.47348526],\n",
       "       [0.52173245],\n",
       "       [0.5119573 ],\n",
       "       [0.49103975],\n",
       "       [0.49511594],\n",
       "       [0.46478072],\n",
       "       [0.52173245],\n",
       "       [0.48570666],\n",
       "       [0.50285023],\n",
       "       [0.47207022],\n",
       "       [0.487232  ],\n",
       "       [0.426586  ],\n",
       "       [0.49927747],\n",
       "       [0.48108143],\n",
       "       [0.49167773],\n",
       "       [0.48360035],\n",
       "       [0.52173245],\n",
       "       [0.5105463 ],\n",
       "       [0.52173245],\n",
       "       [0.5208115 ],\n",
       "       [0.4773017 ],\n",
       "       [0.4962741 ],\n",
       "       [0.52173245],\n",
       "       [0.41995996],\n",
       "       [0.48739454],\n",
       "       [0.48972234],\n",
       "       [0.47113034],\n",
       "       [0.4823362 ],\n",
       "       [0.5020935 ],\n",
       "       [0.5078794 ],\n",
       "       [0.49164447],\n",
       "       [0.4365401 ],\n",
       "       [0.45699275],\n",
       "       [0.5180251 ],\n",
       "       [0.5148502 ],\n",
       "       [0.51589364],\n",
       "       [0.5030757 ],\n",
       "       [0.50238615],\n",
       "       [0.45558628],\n",
       "       [0.5085035 ],\n",
       "       [0.44844466],\n",
       "       [0.49834523],\n",
       "       [0.51629984],\n",
       "       [0.50374794],\n",
       "       [0.5064347 ],\n",
       "       [0.48345813],\n",
       "       [0.4825329 ],\n",
       "       [0.4819732 ],\n",
       "       [0.5078283 ],\n",
       "       [0.49155715],\n",
       "       [0.5127637 ],\n",
       "       [0.52173245],\n",
       "       [0.51487   ],\n",
       "       [0.47191963],\n",
       "       [0.52173245],\n",
       "       [0.5189793 ],\n",
       "       [0.47861204],\n",
       "       [0.47921348],\n",
       "       [0.5198582 ],\n",
       "       [0.5089867 ],\n",
       "       [0.50442445],\n",
       "       [0.52173245],\n",
       "       [0.47948077],\n",
       "       [0.51804847],\n",
       "       [0.4277584 ],\n",
       "       [0.505324  ],\n",
       "       [0.48743868],\n",
       "       [0.52173245],\n",
       "       [0.5115086 ],\n",
       "       [0.45040172],\n",
       "       [0.48224193],\n",
       "       [0.49900767],\n",
       "       [0.4734123 ],\n",
       "       [0.506256  ],\n",
       "       [0.49574763],\n",
       "       [0.50123715],\n",
       "       [0.50481254],\n",
       "       [0.46714345],\n",
       "       [0.4869737 ],\n",
       "       [0.4432855 ],\n",
       "       [0.50744104],\n",
       "       [0.45509014],\n",
       "       [0.49597135],\n",
       "       [0.47862035],\n",
       "       [0.5039754 ],\n",
       "       [0.44056603],\n",
       "       [0.5007932 ],\n",
       "       [0.4691612 ],\n",
       "       [0.49629816],\n",
       "       [0.5001145 ],\n",
       "       [0.5051623 ],\n",
       "       [0.5149944 ],\n",
       "       [0.47258654],\n",
       "       [0.49052873],\n",
       "       [0.51683193],\n",
       "       [0.4972006 ],\n",
       "       [0.51176083],\n",
       "       [0.4848467 ],\n",
       "       [0.5046137 ],\n",
       "       [0.46354046],\n",
       "       [0.5041139 ],\n",
       "       [0.4760526 ],\n",
       "       [0.4814671 ],\n",
       "       [0.51587766],\n",
       "       [0.52173245],\n",
       "       [0.5006499 ],\n",
       "       [0.49300164],\n",
       "       [0.5118887 ],\n",
       "       [0.48697704],\n",
       "       [0.509734  ],\n",
       "       [0.52173245],\n",
       "       [0.4852453 ],\n",
       "       [0.45999503],\n",
       "       [0.48902518],\n",
       "       [0.4211054 ],\n",
       "       [0.507278  ],\n",
       "       [0.52173245],\n",
       "       [0.4950648 ],\n",
       "       [0.4793796 ],\n",
       "       [0.46193528],\n",
       "       [0.52173245],\n",
       "       [0.51883864],\n",
       "       [0.47689041],\n",
       "       [0.49198085],\n",
       "       [0.5187733 ],\n",
       "       [0.49084955],\n",
       "       [0.47068748],\n",
       "       [0.50951034],\n",
       "       [0.45815432],\n",
       "       [0.477989  ],\n",
       "       [0.46333265],\n",
       "       [0.48533866],\n",
       "       [0.48697102],\n",
       "       [0.4909731 ],\n",
       "       [0.46529838],\n",
       "       [0.4864064 ],\n",
       "       [0.46432614],\n",
       "       [0.51242703],\n",
       "       [0.51801926],\n",
       "       [0.5213607 ],\n",
       "       [0.5118093 ],\n",
       "       [0.48713428],\n",
       "       [0.50783473],\n",
       "       [0.52059996],\n",
       "       [0.4926984 ],\n",
       "       [0.5071029 ],\n",
       "       [0.45867184],\n",
       "       [0.50674546],\n",
       "       [0.5007341 ],\n",
       "       [0.5052716 ],\n",
       "       [0.5089073 ],\n",
       "       [0.46706304],\n",
       "       [0.49623412],\n",
       "       [0.50237375],\n",
       "       [0.503958  ],\n",
       "       [0.4555641 ],\n",
       "       [0.45943487],\n",
       "       [0.43941486],\n",
       "       [0.49313122],\n",
       "       [0.5119076 ],\n",
       "       [0.46469066],\n",
       "       [0.48418272],\n",
       "       [0.52173245],\n",
       "       [0.51511365],\n",
       "       [0.5152763 ],\n",
       "       [0.52173245],\n",
       "       [0.4657066 ],\n",
       "       [0.52123755],\n",
       "       [0.52173245],\n",
       "       [0.4894127 ],\n",
       "       [0.51694757],\n",
       "       [0.45182577],\n",
       "       [0.5014701 ],\n",
       "       [0.5146101 ],\n",
       "       [0.51836425],\n",
       "       [0.49222088],\n",
       "       [0.46668705],\n",
       "       [0.50461346],\n",
       "       [0.5035046 ],\n",
       "       [0.52173245],\n",
       "       [0.5052287 ],\n",
       "       [0.47537333],\n",
       "       [0.51476777],\n",
       "       [0.51193726],\n",
       "       [0.4635529 ],\n",
       "       [0.50430524],\n",
       "       [0.50589657],\n",
       "       [0.49692398],\n",
       "       [0.52173245],\n",
       "       [0.45633912],\n",
       "       [0.48606223],\n",
       "       [0.52173245],\n",
       "       [0.4797044 ],\n",
       "       [0.5190267 ],\n",
       "       [0.48538846],\n",
       "       [0.5072798 ],\n",
       "       [0.52173245],\n",
       "       [0.4752722 ],\n",
       "       [0.47083488],\n",
       "       [0.5146594 ],\n",
       "       [0.51619494],\n",
       "       [0.47660023],\n",
       "       [0.5181069 ],\n",
       "       [0.50325626],\n",
       "       [0.4991787 ],\n",
       "       [0.5209229 ],\n",
       "       [0.5153437 ],\n",
       "       [0.47509038],\n",
       "       [0.49253833],\n",
       "       [0.52173245],\n",
       "       [0.50220144],\n",
       "       [0.50814325],\n",
       "       [0.5091007 ],\n",
       "       [0.5047707 ],\n",
       "       [0.51025337],\n",
       "       [0.5122659 ],\n",
       "       [0.46908697],\n",
       "       [0.5135935 ],\n",
       "       [0.5181764 ],\n",
       "       [0.5050584 ],\n",
       "       [0.51057774],\n",
       "       [0.45527983],\n",
       "       [0.47704896],\n",
       "       [0.4504289 ],\n",
       "       [0.5118779 ],\n",
       "       [0.5078258 ],\n",
       "       [0.51663995],\n",
       "       [0.4973685 ],\n",
       "       [0.46968326],\n",
       "       [0.50438696],\n",
       "       [0.49201345],\n",
       "       [0.49495968],\n",
       "       [0.5088877 ],\n",
       "       [0.48869082],\n",
       "       [0.51073515],\n",
       "       [0.48634234],\n",
       "       [0.4991225 ],\n",
       "       [0.518133  ],\n",
       "       [0.52173245],\n",
       "       [0.5062185 ],\n",
       "       [0.5052868 ],\n",
       "       [0.5039014 ],\n",
       "       [0.5216927 ],\n",
       "       [0.51812536],\n",
       "       [0.4774839 ],\n",
       "       [0.4692315 ],\n",
       "       [0.51819664],\n",
       "       [0.5100549 ],\n",
       "       [0.4656929 ],\n",
       "       [0.52173245],\n",
       "       [0.5062301 ],\n",
       "       [0.49271518],\n",
       "       [0.46267697],\n",
       "       [0.48859552],\n",
       "       [0.5063693 ],\n",
       "       [0.4981479 ],\n",
       "       [0.46453795],\n",
       "       [0.5195529 ],\n",
       "       [0.49739516],\n",
       "       [0.50918823],\n",
       "       [0.4988336 ],\n",
       "       [0.52173245],\n",
       "       [0.5088061 ],\n",
       "       [0.52173245],\n",
       "       [0.51843977],\n",
       "       [0.4113709 ],\n",
       "       [0.49562004],\n",
       "       [0.44586435],\n",
       "       [0.48917067],\n",
       "       [0.454714  ],\n",
       "       [0.491386  ],\n",
       "       [0.51363575],\n",
       "       [0.49492636],\n",
       "       [0.49861354],\n",
       "       [0.5046679 ],\n",
       "       [0.46433246],\n",
       "       [0.5040241 ],\n",
       "       [0.4715678 ],\n",
       "       [0.48935005],\n",
       "       [0.45847914],\n",
       "       [0.48913842],\n",
       "       [0.4846954 ],\n",
       "       [0.4726679 ],\n",
       "       [0.5129477 ],\n",
       "       [0.50648284],\n",
       "       [0.48954612],\n",
       "       [0.52173245],\n",
       "       [0.51387036],\n",
       "       [0.52173245],\n",
       "       [0.50214356]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7a8353a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 2ms/step - loss: 0.6942 - accuracy: 0.4910\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.4940\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5050\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5190\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5280\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5300\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5380\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6923 - accuracy: 0.5420\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.5350\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5240\n",
      "16/16 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#Import required packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# Getting the data ready\n",
    "# Generate train dummy data for 1000 Students and dummy test for 500\n",
    "#Columns :Age, Hours of Study & Avg Previous test scores\n",
    "np.random.seed(2018)\n",
    "train_data, test_data = np.random.random((1000, 3)), np.random.random((500, 3))\n",
    "#Generate dummy results for 1000 students : Whether Passed (1) or Failed (0)\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "#Defining the model structure with the required layers, # of neurons, activation function and optimizers\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=3, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Train the model and make predictions\n",
    "model.fit(train_data, labels, epochs=10, batch_size=32)\n",
    "\n",
    "#Make predictions from the trained model\n",
    "predictions = model.predict(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d304977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "94/94 [==============================] - 3s 6ms/step - loss: 0.6936 - accuracy: 0.5033 - val_loss: 0.6931 - val_accuracy: 0.5130\n",
      "Epoch 2/10\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5068 - val_loss: 0.6930 - val_accuracy: 0.5070\n",
      "Epoch 3/10\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5117 - val_loss: 0.6927 - val_accuracy: 0.5170\n",
      "Epoch 4/10\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5092 - val_loss: 0.6926 - val_accuracy: 0.5225\n",
      "Epoch 5/10\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5083 - val_loss: 0.6925 - val_accuracy: 0.5235\n",
      "Epoch 6/10\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5158 - val_loss: 0.6926 - val_accuracy: 0.5190\n",
      "Epoch 7/10\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.5293 - val_loss: 0.6923 - val_accuracy: 0.5225\n",
      "Epoch 8/10\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5213 - val_loss: 0.6928 - val_accuracy: 0.5160\n",
      "Epoch 9/10\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.5147 - val_loss: 0.6928 - val_accuracy: 0.5185\n",
      "Epoch 10/10\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6905 - accuracy: 0.5295 - val_loss: 0.6936 - val_accuracy: 0.5155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17bd558f6d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "np.random.seed(2018)\n",
    "\n",
    "# Generate dummy training dataset\n",
    "x_train = np.random.random((6000,10))\n",
    "y_train = np.random.randint(2, size=(6000, 1))\n",
    "\n",
    "# Generate dummy validation dataset\n",
    "x_val = np.random.random((2000,10))\n",
    "y_val = np.random.randint(2, size=(2000, 1))\n",
    "\n",
    "# Generate dummy test dataset\n",
    "x_test = np.random.random((2000,10))\n",
    "y_test = np.random.randint(2, size=(2000, 1))\n",
    "\n",
    "#Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=10,activation = \"relu\")) #Layer 1\n",
    "model.add(Dense(32,activation = \"relu\"))               #Layer 2\n",
    "model.add(Dense(16,activation = \"relu\"))               #Layer 3\n",
    "model.add(Dense(8,activation = \"relu\"))                #Layer 4\n",
    "model.add(Dense(4,activation = \"relu\"))                #Layer 5\n",
    "model.add(Dense(1,activation = \"sigmoid\"))             #Output Layer\n",
    "\n",
    "#Configure the model\n",
    "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#Train the model\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d799635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#Make predictions from the trained model\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0074aa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e08f25b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(classification_report(y_test,predictions))\n",
    "#r = confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "859b12e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklearn.metrics\n",
    "#e=sklearn.metrics.multilabel_confusion_matrix(y_test, predictions, labels=[\"1\", \"0\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dc3dc9",
   "metadata": {},
   "source": [
    "Working with my dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfd15742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "#getting my datasets\n",
    "ml51 = pd.read_csv(\"train.csv\")\n",
    "ml52 = pd.read_csv(\"test.csv\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a0cf083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the model structure with the required layers, # of neurons, activation function and optimizers\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=3, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26d5608f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49\n",
      "Trainable params: 49\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8bc3b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.6972 - accuracy: 0.4920\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.4860\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 0.4890\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.4830\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.4890\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.4880\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.4930\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.4840\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4930\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17bd54ed700>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model and make predictions\n",
    "model.fit(train_data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1defaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#Make predictions from the trained model\n",
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "213c6ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5002095 ],\n",
       "       [0.49118486],\n",
       "       [0.49547192],\n",
       "       [0.4896206 ],\n",
       "       [0.51817006],\n",
       "       [0.505526  ],\n",
       "       [0.49169418],\n",
       "       [0.49258992],\n",
       "       [0.49773836],\n",
       "       [0.49656543],\n",
       "       [0.4974722 ],\n",
       "       [0.49198908],\n",
       "       [0.48428857],\n",
       "       [0.50149876],\n",
       "       [0.4671584 ],\n",
       "       [0.49445298],\n",
       "       [0.4814535 ],\n",
       "       [0.50213206],\n",
       "       [0.47990003],\n",
       "       [0.48588723],\n",
       "       [0.4551114 ],\n",
       "       [0.51686984],\n",
       "       [0.4710755 ],\n",
       "       [0.50654167],\n",
       "       [0.4701889 ],\n",
       "       [0.49300605],\n",
       "       [0.5093954 ],\n",
       "       [0.5001451 ],\n",
       "       [0.4871435 ],\n",
       "       [0.51485604],\n",
       "       [0.49207047],\n",
       "       [0.50453407],\n",
       "       [0.51269984],\n",
       "       [0.48589   ],\n",
       "       [0.50699645],\n",
       "       [0.46601215],\n",
       "       [0.48848   ],\n",
       "       [0.50048906],\n",
       "       [0.48974586],\n",
       "       [0.45306328],\n",
       "       [0.49687946],\n",
       "       [0.49739137],\n",
       "       [0.4954341 ],\n",
       "       [0.48996013],\n",
       "       [0.502293  ],\n",
       "       [0.47675475],\n",
       "       [0.4863215 ],\n",
       "       [0.47265366],\n",
       "       [0.49775332],\n",
       "       [0.5006004 ],\n",
       "       [0.5192771 ],\n",
       "       [0.5002028 ],\n",
       "       [0.4914637 ],\n",
       "       [0.4904234 ],\n",
       "       [0.50484943],\n",
       "       [0.49238017],\n",
       "       [0.49547192],\n",
       "       [0.4851936 ],\n",
       "       [0.47005928],\n",
       "       [0.48806003],\n",
       "       [0.5071956 ],\n",
       "       [0.49883485],\n",
       "       [0.50933915],\n",
       "       [0.4787498 ],\n",
       "       [0.46111444],\n",
       "       [0.50241613],\n",
       "       [0.49547192],\n",
       "       [0.49829605],\n",
       "       [0.49547192],\n",
       "       [0.4942864 ],\n",
       "       [0.48195294],\n",
       "       [0.492471  ],\n",
       "       [0.4949457 ],\n",
       "       [0.50857514],\n",
       "       [0.5112871 ],\n",
       "       [0.5002205 ],\n",
       "       [0.48630172],\n",
       "       [0.49276304],\n",
       "       [0.45085403],\n",
       "       [0.4674303 ],\n",
       "       [0.5019787 ],\n",
       "       [0.46509764],\n",
       "       [0.49825418],\n",
       "       [0.49547192],\n",
       "       [0.49964148],\n",
       "       [0.48964125],\n",
       "       [0.50480604],\n",
       "       [0.4784573 ],\n",
       "       [0.50563264],\n",
       "       [0.49871117],\n",
       "       [0.47146827],\n",
       "       [0.47085625],\n",
       "       [0.49004468],\n",
       "       [0.48185688],\n",
       "       [0.5056146 ],\n",
       "       [0.48118907],\n",
       "       [0.46469575],\n",
       "       [0.53286874],\n",
       "       [0.49081624],\n",
       "       [0.49270275],\n",
       "       [0.4918481 ],\n",
       "       [0.45483875],\n",
       "       [0.49419224],\n",
       "       [0.4873172 ],\n",
       "       [0.48969162],\n",
       "       [0.52220386],\n",
       "       [0.45206994],\n",
       "       [0.49398977],\n",
       "       [0.48337117],\n",
       "       [0.489765  ],\n",
       "       [0.4994354 ],\n",
       "       [0.4804225 ],\n",
       "       [0.4965647 ],\n",
       "       [0.4609266 ],\n",
       "       [0.4906235 ],\n",
       "       [0.48587215],\n",
       "       [0.49547192],\n",
       "       [0.49523538],\n",
       "       [0.50807625],\n",
       "       [0.4901698 ],\n",
       "       [0.4936501 ],\n",
       "       [0.50549114],\n",
       "       [0.48995996],\n",
       "       [0.5200985 ],\n",
       "       [0.4848418 ],\n",
       "       [0.45382878],\n",
       "       [0.4910401 ],\n",
       "       [0.48906812],\n",
       "       [0.47364432],\n",
       "       [0.5152426 ],\n",
       "       [0.48562026],\n",
       "       [0.49087572],\n",
       "       [0.49809396],\n",
       "       [0.51156694],\n",
       "       [0.48168597],\n",
       "       [0.487543  ],\n",
       "       [0.5050911 ],\n",
       "       [0.4777827 ],\n",
       "       [0.48772076],\n",
       "       [0.49299082],\n",
       "       [0.50305605],\n",
       "       [0.48388714],\n",
       "       [0.48885155],\n",
       "       [0.4930732 ],\n",
       "       [0.51150554],\n",
       "       [0.49547192],\n",
       "       [0.47889796],\n",
       "       [0.47891748],\n",
       "       [0.50081295],\n",
       "       [0.486248  ],\n",
       "       [0.49982357],\n",
       "       [0.47706863],\n",
       "       [0.5238715 ],\n",
       "       [0.5058556 ],\n",
       "       [0.4761698 ],\n",
       "       [0.48845437],\n",
       "       [0.48595697],\n",
       "       [0.49547192],\n",
       "       [0.4896842 ],\n",
       "       [0.49827403],\n",
       "       [0.49269232],\n",
       "       [0.4968768 ],\n",
       "       [0.5008574 ],\n",
       "       [0.48111093],\n",
       "       [0.49547192],\n",
       "       [0.5003506 ],\n",
       "       [0.46276176],\n",
       "       [0.49505183],\n",
       "       [0.48234206],\n",
       "       [0.4819701 ],\n",
       "       [0.49936157],\n",
       "       [0.514833  ],\n",
       "       [0.5032769 ],\n",
       "       [0.48630425],\n",
       "       [0.4713017 ],\n",
       "       [0.46423918],\n",
       "       [0.4870844 ],\n",
       "       [0.48192665],\n",
       "       [0.50216883],\n",
       "       [0.5173561 ],\n",
       "       [0.49931183],\n",
       "       [0.47304848],\n",
       "       [0.48931298],\n",
       "       [0.4748698 ],\n",
       "       [0.4858446 ],\n",
       "       [0.4926027 ],\n",
       "       [0.49619365],\n",
       "       [0.4901266 ],\n",
       "       [0.4907794 ],\n",
       "       [0.47531796],\n",
       "       [0.48120892],\n",
       "       [0.5148897 ],\n",
       "       [0.507665  ],\n",
       "       [0.48913062],\n",
       "       [0.45856312],\n",
       "       [0.4997456 ],\n",
       "       [0.46203253],\n",
       "       [0.48198158],\n",
       "       [0.48208898],\n",
       "       [0.4992172 ],\n",
       "       [0.5045426 ],\n",
       "       [0.4814653 ],\n",
       "       [0.5019684 ],\n",
       "       [0.47571993],\n",
       "       [0.49455416],\n",
       "       [0.4721596 ],\n",
       "       [0.48113   ],\n",
       "       [0.5081217 ],\n",
       "       [0.49735215],\n",
       "       [0.50607616],\n",
       "       [0.49765682],\n",
       "       [0.4829984 ],\n",
       "       [0.4374116 ],\n",
       "       [0.47456118],\n",
       "       [0.4671831 ],\n",
       "       [0.5161382 ],\n",
       "       [0.4742123 ],\n",
       "       [0.48596567],\n",
       "       [0.49831134],\n",
       "       [0.49067706],\n",
       "       [0.4804399 ],\n",
       "       [0.507864  ],\n",
       "       [0.4943088 ],\n",
       "       [0.49467164],\n",
       "       [0.4739735 ],\n",
       "       [0.48782673],\n",
       "       [0.48841608],\n",
       "       [0.48806822],\n",
       "       [0.4922012 ],\n",
       "       [0.47099397],\n",
       "       [0.51094365],\n",
       "       [0.49547192],\n",
       "       [0.46969378],\n",
       "       [0.5179951 ],\n",
       "       [0.48010257],\n",
       "       [0.4837829 ],\n",
       "       [0.48930377],\n",
       "       [0.4913908 ],\n",
       "       [0.48222128],\n",
       "       [0.50147134],\n",
       "       [0.49018085],\n",
       "       [0.4918708 ],\n",
       "       [0.5202806 ],\n",
       "       [0.48394993],\n",
       "       [0.4692003 ],\n",
       "       [0.5012173 ],\n",
       "       [0.4935065 ],\n",
       "       [0.48339164],\n",
       "       [0.51682204],\n",
       "       [0.47217137],\n",
       "       [0.4900602 ],\n",
       "       [0.49284756],\n",
       "       [0.494992  ],\n",
       "       [0.49541822],\n",
       "       [0.48928133],\n",
       "       [0.49183288],\n",
       "       [0.49079514],\n",
       "       [0.50314164],\n",
       "       [0.49547192],\n",
       "       [0.5011609 ],\n",
       "       [0.48126394],\n",
       "       [0.4928743 ],\n",
       "       [0.47805646],\n",
       "       [0.51154673],\n",
       "       [0.4670417 ],\n",
       "       [0.48815233],\n",
       "       [0.51391935],\n",
       "       [0.5035265 ],\n",
       "       [0.458795  ],\n",
       "       [0.50687104],\n",
       "       [0.49547192],\n",
       "       [0.49251807],\n",
       "       [0.48326027],\n",
       "       [0.49636075],\n",
       "       [0.5173955 ],\n",
       "       [0.47365317],\n",
       "       [0.49380106],\n",
       "       [0.44194093],\n",
       "       [0.4897958 ],\n",
       "       [0.51987183],\n",
       "       [0.4875777 ],\n",
       "       [0.4825862 ],\n",
       "       [0.49247402],\n",
       "       [0.4852362 ],\n",
       "       [0.49393868],\n",
       "       [0.48816463],\n",
       "       [0.49407628],\n",
       "       [0.5023043 ],\n",
       "       [0.49474484],\n",
       "       [0.49773377],\n",
       "       [0.49649277],\n",
       "       [0.49028826],\n",
       "       [0.4862532 ],\n",
       "       [0.48894432],\n",
       "       [0.46967053],\n",
       "       [0.5004093 ],\n",
       "       [0.46267965],\n",
       "       [0.5012934 ],\n",
       "       [0.46595892],\n",
       "       [0.49518156],\n",
       "       [0.48665524],\n",
       "       [0.49435782],\n",
       "       [0.5179817 ],\n",
       "       [0.48603114],\n",
       "       [0.49051344],\n",
       "       [0.4991696 ],\n",
       "       [0.49547192],\n",
       "       [0.5155436 ],\n",
       "       [0.49547192],\n",
       "       [0.5095993 ],\n",
       "       [0.49375638],\n",
       "       [0.49466002],\n",
       "       [0.48464867],\n",
       "       [0.46311003],\n",
       "       [0.47546175],\n",
       "       [0.4827719 ],\n",
       "       [0.5020644 ],\n",
       "       [0.4876117 ],\n",
       "       [0.47995043],\n",
       "       [0.4830095 ],\n",
       "       [0.49487507],\n",
       "       [0.49555233],\n",
       "       [0.49594024],\n",
       "       [0.47400418],\n",
       "       [0.4926232 ],\n",
       "       [0.47453696],\n",
       "       [0.49547192],\n",
       "       [0.49456707],\n",
       "       [0.494237  ],\n",
       "       [0.5026217 ],\n",
       "       [0.49470517],\n",
       "       [0.45682806],\n",
       "       [0.51389074],\n",
       "       [0.4922341 ],\n",
       "       [0.49396363],\n",
       "       [0.49405345],\n",
       "       [0.508703  ],\n",
       "       [0.49547192],\n",
       "       [0.5108093 ],\n",
       "       [0.49670556],\n",
       "       [0.49071   ],\n",
       "       [0.4951116 ],\n",
       "       [0.48711535],\n",
       "       [0.47032765],\n",
       "       [0.49650162],\n",
       "       [0.5001567 ],\n",
       "       [0.4994396 ],\n",
       "       [0.45271564],\n",
       "       [0.49547192],\n",
       "       [0.4937563 ],\n",
       "       [0.45799175],\n",
       "       [0.4959845 ],\n",
       "       [0.48809192],\n",
       "       [0.47689602],\n",
       "       [0.48365638],\n",
       "       [0.48027477],\n",
       "       [0.5212297 ],\n",
       "       [0.49271825],\n",
       "       [0.4926247 ],\n",
       "       [0.49547192],\n",
       "       [0.5013188 ],\n",
       "       [0.5137469 ],\n",
       "       [0.50794774],\n",
       "       [0.49898985],\n",
       "       [0.465114  ],\n",
       "       [0.5047135 ],\n",
       "       [0.5168915 ],\n",
       "       [0.51965076],\n",
       "       [0.48975083],\n",
       "       [0.4871413 ],\n",
       "       [0.5146402 ],\n",
       "       [0.49428856],\n",
       "       [0.48814815],\n",
       "       [0.462062  ],\n",
       "       [0.47842348],\n",
       "       [0.48381302],\n",
       "       [0.50106734],\n",
       "       [0.49095136],\n",
       "       [0.49530104],\n",
       "       [0.4909854 ],\n",
       "       [0.49547192],\n",
       "       [0.48967198],\n",
       "       [0.49541798],\n",
       "       [0.47209993],\n",
       "       [0.47462344],\n",
       "       [0.48529798],\n",
       "       [0.5000111 ],\n",
       "       [0.4819916 ],\n",
       "       [0.46419024],\n",
       "       [0.47145826],\n",
       "       [0.4725697 ],\n",
       "       [0.50368214],\n",
       "       [0.45382196],\n",
       "       [0.48770317],\n",
       "       [0.49420643],\n",
       "       [0.46590906],\n",
       "       [0.46682018],\n",
       "       [0.49031353],\n",
       "       [0.45476028],\n",
       "       [0.4980667 ],\n",
       "       [0.4878383 ],\n",
       "       [0.49547192],\n",
       "       [0.49232298],\n",
       "       [0.48291406],\n",
       "       [0.49995157],\n",
       "       [0.49547192],\n",
       "       [0.49381033],\n",
       "       [0.51852316],\n",
       "       [0.49604586],\n",
       "       [0.50493395],\n",
       "       [0.49125934],\n",
       "       [0.5238496 ],\n",
       "       [0.49825367],\n",
       "       [0.4708253 ],\n",
       "       [0.49380934],\n",
       "       [0.49390098],\n",
       "       [0.49825078],\n",
       "       [0.4990838 ],\n",
       "       [0.4797897 ],\n",
       "       [0.46676847],\n",
       "       [0.47602674],\n",
       "       [0.50428796],\n",
       "       [0.46778226],\n",
       "       [0.5011302 ],\n",
       "       [0.47153193],\n",
       "       [0.47442353],\n",
       "       [0.5188438 ],\n",
       "       [0.48458716],\n",
       "       [0.4881198 ],\n",
       "       [0.46803167],\n",
       "       [0.47373238],\n",
       "       [0.50322086],\n",
       "       [0.50417805],\n",
       "       [0.49010205],\n",
       "       [0.49547192],\n",
       "       [0.47212777],\n",
       "       [0.4704377 ],\n",
       "       [0.46932945],\n",
       "       [0.49926397],\n",
       "       [0.48531467],\n",
       "       [0.4681138 ],\n",
       "       [0.4900093 ],\n",
       "       [0.49547192],\n",
       "       [0.4783796 ],\n",
       "       [0.45654246],\n",
       "       [0.49499264],\n",
       "       [0.45976698],\n",
       "       [0.49367726],\n",
       "       [0.48742932],\n",
       "       [0.505799  ],\n",
       "       [0.46951163],\n",
       "       [0.49583116],\n",
       "       [0.48139986],\n",
       "       [0.49547192],\n",
       "       [0.50262517],\n",
       "       [0.5079471 ],\n",
       "       [0.4731435 ],\n",
       "       [0.46089917],\n",
       "       [0.52809995],\n",
       "       [0.44098356],\n",
       "       [0.46140754],\n",
       "       [0.47456053],\n",
       "       [0.49110502],\n",
       "       [0.4825636 ],\n",
       "       [0.49547192],\n",
       "       [0.49444145],\n",
       "       [0.5166894 ],\n",
       "       [0.49115607],\n",
       "       [0.48740277],\n",
       "       [0.45876977],\n",
       "       [0.47987744],\n",
       "       [0.4448459 ],\n",
       "       [0.4872073 ],\n",
       "       [0.4942506 ],\n",
       "       [0.4924478 ],\n",
       "       [0.5102556 ],\n",
       "       [0.48725444],\n",
       "       [0.49361905],\n",
       "       [0.48488   ],\n",
       "       [0.5119958 ],\n",
       "       [0.4751591 ],\n",
       "       [0.46141136],\n",
       "       [0.49547192],\n",
       "       [0.5079439 ],\n",
       "       [0.4884491 ],\n",
       "       [0.51371837],\n",
       "       [0.49078646],\n",
       "       [0.49856305],\n",
       "       [0.49301094],\n",
       "       [0.5185204 ],\n",
       "       [0.48285502],\n",
       "       [0.51014405],\n",
       "       [0.49079886],\n",
       "       [0.49360353],\n",
       "       [0.4867005 ],\n",
       "       [0.4678262 ],\n",
       "       [0.4879307 ],\n",
       "       [0.4927832 ],\n",
       "       [0.49547192],\n",
       "       [0.45928156]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5a8ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target=ml51[\"Label\"]\n",
    "target1=x_train[\"Label\"]\n",
    "target2=x_val[\"Label\"]\n",
    "target3=x_test[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e9541120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "177/177 [==============================] - 2s 4ms/step - loss: 3411.2532 - accuracy: 0.0805 - val_loss: -7197.7651 - val_accuracy: 0.0069\n",
      "Epoch 2/10\n",
      "177/177 [==============================] - 1s 5ms/step - loss: -8506.3545 - accuracy: 0.0011 - val_loss: -29035.0703 - val_accuracy: 0.0015\n",
      "Epoch 3/10\n",
      "177/177 [==============================] - 1s 3ms/step - loss: -49570.6523 - accuracy: 0.0021 - val_loss: -138969.8750 - val_accuracy: 7.3594e-04\n",
      "Epoch 4/10\n",
      "177/177 [==============================] - 0s 3ms/step - loss: -383923.4062 - accuracy: 0.0045 - val_loss: -1083105.3750 - val_accuracy: 7.3594e-04\n",
      "Epoch 5/10\n",
      "177/177 [==============================] - 0s 3ms/step - loss: -2880647.7500 - accuracy: 4.4158e-04 - val_loss: -4808069.0000 - val_accuracy: 0.0028\n",
      "Epoch 6/10\n",
      "177/177 [==============================] - 0s 2ms/step - loss: -10445785.0000 - accuracy: 7.0653e-04 - val_loss: -14124551.0000 - val_accuracy: 7.3594e-04\n",
      "Epoch 7/10\n",
      "177/177 [==============================] - 0s 2ms/step - loss: -41523340.0000 - accuracy: 0.0014 - val_loss: -59222532.0000 - val_accuracy: 7.3594e-04\n",
      "Epoch 8/10\n",
      "177/177 [==============================] - 0s 3ms/step - loss: -144526848.0000 - accuracy: 7.9484e-04 - val_loss: -171714656.0000 - val_accuracy: 7.3594e-04\n",
      "Epoch 9/10\n",
      "177/177 [==============================] - 0s 3ms/step - loss: -374169344.0000 - accuracy: 6.1821e-04 - val_loss: -312316704.0000 - val_accuracy: 7.3594e-04\n",
      "Epoch 10/10\n",
      "177/177 [==============================] - 0s 3ms/step - loss: -815043392.0000 - accuracy: 4.4158e-04 - val_loss: -649684096.0000 - val_accuracy: 7.3594e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17bdbe23fd0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "\n",
    "# Generate dummy training dataset\n",
    "x_train = ml51.sample(frac = 0.5)\n",
    "y_train = target1\n",
    "\n",
    "# Generate dummy validation dataset\n",
    "x_val = ml51.sample(frac = 0.3)\n",
    "y_val = target2\n",
    "\n",
    "# Generate dummy test dataset\n",
    "x_test = ml51.sample(frac = 0.2)\n",
    "y_test = target3\n",
    "\n",
    "#Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=80,activation = \"relu\")) #Layer 1\n",
    "model.add(Dense(32,activation = \"relu\"))               #Layer 2\n",
    "model.add(Dense(16,activation = \"relu\"))               #Layer 3\n",
    "model.add(Dense(8,activation = \"relu\"))                #Layer 4\n",
    "model.add(Dense(4,activation = \"relu\"))                #Layer 5\n",
    "model.add(Dense(1,activation = \"sigmoid\"))             #Output Layer\n",
    "\n",
    "#Configure the model\n",
    "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#Train the model\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e1e00988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#Make predictions from the trained model\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "16c07840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4b3fadeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=y_test, y_pred=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7091cf9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 3648    0    0    0    0    0    0    0    0    0]\n",
      " [   0    1    0    0    0    0    0    0    0    0    0]\n",
      " [   0  176    0    0    0    0    0    0    0    0    0]\n",
      " [   0   18    0    0    0    0    0    0    0    0    0]\n",
      " [   0  369    0    0    0    0    0    0    0    0    0]\n",
      " [   0    8    0    0    0    0    0    0    0    0    0]\n",
      " [   0    8    0    0    0    0    0    0    0    0    0]\n",
      " [   0   13    0    0    0    0    0    0    0    0    0]\n",
      " [   0  278    0    0    0    0    0    0    0    0    0]\n",
      " [   0    4    0    0    0    0    0    0    0    0    0]\n",
      " [   0    6    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e81bcc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      3648\n",
      "           1       0.00      1.00      0.00         1\n",
      "           2       0.00      0.00      0.00       176\n",
      "           3       0.00      0.00      0.00        18\n",
      "           4       0.00      0.00      0.00       369\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.00      0.00      0.00         8\n",
      "           7       0.00      0.00      0.00        13\n",
      "          10       0.00      0.00      0.00       278\n",
      "          11       0.00      0.00      0.00         4\n",
      "          12       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.00      4529\n",
      "   macro avg       0.00      0.09      0.00      4529\n",
      "weighted avg       0.00      0.00      0.00      4529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
